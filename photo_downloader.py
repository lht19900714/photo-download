"""PhotoPlus ç›´æ’­ç…§ç‰‡è‡ªåŠ¨ä¸‹è½½å·¥å…·"""

import asyncio
import json
import logging
import os
import sys
import time
from datetime import datetime
from io import BytesIO
from typing import List, Dict, Optional

import requests
from playwright.async_api import async_playwright, Page

try:
    import dropbox
    import dropbox.exceptions
    DROPBOX_AVAILABLE = True
except ImportError:
    DROPBOX_AVAILABLE = False
    logging.warning("Dropbox SDKæœªå®‰è£…ï¼ŒDropboxåŠŸèƒ½å°†ä¸å¯ç”¨")

from config import (
    TARGET_URL,
    CHECK_INTERVAL,
    PHOTO_DIR,
    DOWNLOADED_HISTORY,
    MAX_CONNECTION_FAILURES,
    MAX_DOWNLOAD_RETRIES,
    HEADLESS,
    TIMEOUT,
    SCROLL_PAUSE_TIME,
    MAX_SCROLL_ATTEMPTS,
    PHOTO_DETAIL_LOAD_WAIT,
    PHOTO_CLOSE_WAIT,
    PAGE_RENDER_WAIT,
    PHOTO_ITEM_SELECTOR,
    PHOTO_CLICK_SELECTOR,
    VIEW_ORIGINAL_SELECTOR,
    FRESH_START,
    DEBUG_FINGERPRINT_EXTRACTION,
    DROPBOX_ACCESS_TOKEN,
    DROPBOX_SAVE_PATH,
    SAVE_TO_LOCAL,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# å¸¸é‡
SEPARATOR = "=" * 60


# ============ Dropbox è¾…åŠ©å‡½æ•° ============

def init_dropbox_client(access_token: str = None,
                        refresh_token: str = None,
                        app_key: str = None,
                        app_secret: str = None) -> Optional[object]:
    """
    åˆå§‹åŒ– Dropbox å®¢æˆ·ç«¯ï¼Œæ”¯æŒä¸¤ç§è®¤è¯æ–¹å¼

    æ–¹å¼ 1ï¼ˆæ¨èï¼‰ï¼šä½¿ç”¨ Refresh Tokenï¼ˆé€‚åˆé•¿æœŸè¿è¡Œï¼‰
        - refresh_token: Dropbox Refresh Token
        - app_key: Dropbox App Key
        - app_secret: Dropbox App Secret

    æ–¹å¼ 2ï¼ˆæ—§æ–¹å¼ï¼‰ï¼šä½¿ç”¨ Access Tokenï¼ˆ4å°æ—¶æœ‰æ•ˆæœŸï¼‰
        - access_token: Dropbox Access Token

    Args:
        access_token: Dropbox è®¿é—®ä»¤ç‰Œï¼ˆæ—§æ–¹å¼ï¼Œå¯é€‰ï¼‰
        refresh_token: Dropbox åˆ·æ–°ä»¤ç‰Œï¼ˆæ–°æ–¹å¼ï¼Œæ¨èï¼‰
        app_key: Dropbox App Keyï¼ˆæ–°æ–¹å¼éœ€è¦ï¼‰
        app_secret: Dropbox App Secretï¼ˆæ–°æ–¹å¼éœ€è¦ï¼‰

    Returns:
        Dropbox å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¦‚æœåˆå§‹åŒ–å¤±è´¥åˆ™è¿”å› None
    """
    if not DROPBOX_AVAILABLE:
        logging.error("Dropbox SDK æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ Dropbox åŠŸèƒ½")
        logging.error("è¯·è¿è¡Œ: uv add dropbox")
        return None

    # ä¼˜å…ˆä½¿ç”¨ Refresh Tokenï¼ˆæ¨èæ–¹å¼ï¼‰
    if refresh_token and app_key and app_secret:
        logging.info("ğŸ“‹ ä½¿ç”¨ Refresh Token è®¤è¯ï¼ˆæ¨èæ–¹å¼ï¼‰")
        try:
            client = dropbox.Dropbox(
                oauth2_refresh_token=refresh_token,
                app_key=app_key,
                app_secret=app_secret
            )
            # éªŒè¯ Token æœ‰æ•ˆæ€§
            account = client.users_get_current_account()
            logging.info(f"âœ… Dropbox è®¤è¯æˆåŠŸ: {account.name.display_name}")
            return client
        except dropbox.exceptions.AuthError as e:
            logging.error(f"Dropbox Refresh Token è®¤è¯å¤±è´¥: {e}")
            logging.error("è¯·æ£€æŸ¥ DROPBOX_REFRESH_TOKENã€DROPBOX_APP_KEY å’Œ DROPBOX_APP_SECRET é…ç½®")
            return None
        except Exception as e:
            logging.error(f"Dropbox å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    # é™çº§ä½¿ç”¨ Access Tokenï¼ˆæ—§æ–¹å¼ï¼Œ4å°æ—¶æœ‰æ•ˆæœŸï¼‰
    elif access_token:
        logging.warning("âš ï¸ ä½¿ç”¨ Access Token è®¤è¯ï¼ˆ4å°æ—¶æœ‰æ•ˆæœŸï¼Œä¸æ¨èï¼‰")
        logging.warning("âš ï¸ å»ºè®®åˆ‡æ¢åˆ° Refresh Token ä»¥æ”¯æŒé•¿æœŸè¿è¡Œ")
        try:
            client = dropbox.Dropbox(access_token)
            # éªŒè¯ Token æœ‰æ•ˆæ€§
            account = client.users_get_current_account()
            logging.info(f"âœ… Dropbox è®¤è¯æˆåŠŸ: {account.name.display_name}")
            return client
        except dropbox.exceptions.AuthError as e:
            logging.error(f"Dropbox è®¤è¯å¤±è´¥: {e}")
            logging.error("è¯·æ£€æŸ¥ DROPBOX_ACCESS_TOKEN é…ç½®æ˜¯å¦æ­£ç¡®")
            logging.error("å¦‚æœ Token å·²è¿‡æœŸï¼ˆ4å°æ—¶ï¼‰ï¼Œè¯·åˆ‡æ¢åˆ° Refresh Token æ–¹å¼")
            return None
        except Exception as e:
            logging.error(f"Dropbox å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    else:
        logging.info("â„¹ï¸ æœªé…ç½® Dropbox è®¤è¯ä¿¡æ¯ï¼Œè·³è¿‡ Dropbox åŠŸèƒ½")
        return None


def ensure_dropbox_path(client: object, path: str) -> bool:
    """
    ç¡®ä¿ Dropbox è·¯å¾„å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º

    Args:
        client: Dropbox å®¢æˆ·ç«¯å®ä¾‹
        path: Dropbox è·¯å¾„ï¼ˆå¦‚ /PhotoPlus/photosï¼‰

    Returns:
        True è¡¨ç¤ºè·¯å¾„å¯ç”¨ï¼ŒFalse è¡¨ç¤ºè·¯å¾„åˆ›å»ºå¤±è´¥
    """
    if not client:
        return False

    try:
        # å°è¯•è·å–è·¯å¾„å…ƒæ•°æ®
        client.files_get_metadata(path)
        logging.info(f"Dropbox è·¯å¾„å·²å­˜åœ¨: {path}")
        return True
    except dropbox.exceptions.ApiError as e:
        # è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º
        if isinstance(e.error, dropbox.files.GetMetadataError):
            try:
                client.files_create_folder_v2(path)
                logging.info(f"âœ“ å·²åˆ›å»º Dropbox ç›®å½•: {path}")
                return True
            except dropbox.exceptions.ApiError as create_error:
                logging.error(f"åˆ›å»º Dropbox ç›®å½•å¤±è´¥: {create_error}")
                return False
        else:
            logging.error(f"æ£€æŸ¥ Dropbox è·¯å¾„å¤±è´¥: {e}")
            return False
    except Exception as e:
        logging.error(f"Dropbox è·¯å¾„æ“ä½œå¤±è´¥: {e}")
        return False


class DownloadHistory:
    """
    ç®¡ç†å·²ä¸‹è½½æ–‡ä»¶è®°å½• (v2.0 - åŸºäºæŒ‡çº¹å»é‡)

    æ•°æ®æ ¼å¼:
    {
        "version": "2.0",
        "downloads": {
            "æŒ‡çº¹(ç¼©ç•¥å›¾æ–‡ä»¶å)": {
                "original_filename": "åŸå›¾æ–‡ä»¶å.jpg",
                "thumbnail_url": "ç¼©ç•¥å›¾URL",
                "download_time": "2025-11-17 10:30:00"
            },
            ...
        },
        "last_update": "2025-11-17 10:30:00"
    }
    """

    def __init__(self, history_file: str):
        self.history_file = history_file
        self.version: str = "2.0"
        self.downloads: Dict[str, Dict] = {}  # æŒ‡çº¹ -> ä¸‹è½½ä¿¡æ¯æ˜ å°„
        self._load_history()

    def _load_history(self):
        """ä»JSONæ–‡ä»¶åŠ è½½å†å²è®°å½•ï¼ˆä»…æ”¯æŒv2.0æ ¼å¼ï¼‰"""
        if not os.path.exists(self.history_file):
            logging.info("å†å²è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return

        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥ç‰ˆæœ¬
            version = data.get('version', 'unknown')
            if version != '2.0':
                logging.warning(f"ä¸å…¼å®¹çš„æ•°æ®æ ¼å¼ç‰ˆæœ¬: {version}ï¼Œå°†åˆ›å»ºæ–°çš„å†å²è®°å½•")
                self.downloads = {}
                return

            # åŠ è½½v2.0æ ¼å¼æ•°æ®
            self.downloads = data.get('downloads', {})
            logging.info(f"å·²åŠ è½½ {len(self.downloads)} æ¡å†å²è®°å½•")

        except Exception as e:
            logging.warning(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°çš„å†å²è®°å½•")
            self.downloads = {}

    def save_history(self):
        """ä¿å­˜å†å²è®°å½•åˆ°JSONæ–‡ä»¶ï¼ˆv2.0æ ¼å¼ï¼‰"""
        try:
            data = {
                'version': self.version,
                'downloads': self.downloads,
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

    def is_downloaded_by_fingerprint(self, fingerprint: str) -> bool:
        """æ£€æŸ¥æŒ‡çº¹æ˜¯å¦å·²ä¸‹è½½"""
        return fingerprint in self.downloads

    def add_download_record(self, fingerprint: str, original_filename: str, thumbnail_url: str):
        """
        æ·»åŠ æ–°ä¸‹è½½è®°å½•

        Args:
            fingerprint: ç…§ç‰‡æŒ‡çº¹ï¼ˆç¼©ç•¥å›¾æ–‡ä»¶åï¼‰
            original_filename: åŸå›¾æ–‡ä»¶åï¼ˆä¿å­˜åˆ°photos/çš„æ–‡ä»¶åï¼‰
            thumbnail_url: ç¼©ç•¥å›¾URL
        """
        self.downloads[fingerprint] = {
            "original_filename": original_filename,
            "thumbnail_url": thumbnail_url,
            "download_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


async def scroll_to_load_all(page: Page):
    """æ»šåŠ¨ç…§ç‰‡å®¹å™¨ç›´åˆ°æ‰€æœ‰ç…§ç‰‡åŠ è½½å®Œæˆ"""
    logging.info("å¼€å§‹æ»šåŠ¨åŠ è½½æ‰€æœ‰ç…§ç‰‡...")

    # è·å–ç…§ç‰‡å®¹å™¨å…ƒç´ 
    container_selector = "div.photo-content.container"
    container = page.locator(container_selector).first

    # ç­‰å¾…å®¹å™¨åŠ è½½
    await container.wait_for(timeout=10000)

    # æ”¹ç”¨ç…§ç‰‡å…ƒç´ æ•°é‡åˆ¤æ–­
    last_photo_count = 0
    scroll_count = 0
    no_change_count = 0  # è¿ç»­æœªå˜åŒ–æ¬¡æ•°

    while scroll_count < MAX_SCROLL_ATTEMPTS:
        # æ»šåŠ¨å®¹å™¨åˆ°åº•éƒ¨ï¼ˆè€Œä¸æ˜¯æ•´ä¸ªé¡µé¢ï¼‰
        await container.evaluate("""
            (element) => {
                element.scrollTop = element.scrollHeight;
            }
        """)
        scroll_count += 1

        # ç­‰å¾…å†…å®¹åŠ è½½
        await asyncio.sleep(SCROLL_PAUSE_TIME)

        # æ£€æŸ¥ç…§ç‰‡å…ƒç´ æ•°é‡
        current_photo_count = await page.locator(PHOTO_ITEM_SELECTOR).count()

        if current_photo_count > last_photo_count:
            # æœ‰æ–°ç…§ç‰‡åŠ è½½
            logging.info(f"æ»šåŠ¨ä¸­... ({scroll_count} æ¬¡) - å½“å‰ {current_photo_count} å¼ ç…§ç‰‡")
            last_photo_count = current_photo_count
            no_change_count = 0
        else:
            # ç…§ç‰‡æ•°é‡æœªå˜åŒ–
            no_change_count += 1
            logging.info(f"æ»šåŠ¨ä¸­... ({scroll_count} æ¬¡) - ç…§ç‰‡æ•°é‡æœªå˜åŒ– ({no_change_count}/3)")

            # è¿ç»­3æ¬¡æœªå˜åŒ–åˆ™è®¤ä¸ºåŠ è½½å®Œæˆ
            if no_change_count >= 3:
                logging.info(f"âœ“ æ»šåŠ¨å®Œæˆï¼Œå…±æ»šåŠ¨ {scroll_count} æ¬¡ï¼Œæ€»è®¡ {current_photo_count} å¼ ç…§ç‰‡")
                break

    if scroll_count >= MAX_SCROLL_ATTEMPTS:
        logging.warning(f"è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•° {MAX_SCROLL_ATTEMPTS}ï¼Œåœæ­¢æ»šåŠ¨ï¼ˆå½“å‰ {last_photo_count} å¼ ç…§ç‰‡ï¼‰")


class PhotoExtractor:
    """æå–é¡µé¢ä¸Šæ‰€æœ‰ç…§ç‰‡çš„åŸå›¾URLï¼ˆåŸºäºæŒ‡çº¹å»é‡ï¼‰"""

    def _extract_filename_from_thumbnail(self, url: str, fallback_index: int = None) -> str:
        """
        ä»ç¼©ç•¥å›¾URLæå–æ–‡ä»¶åä½œä¸ºæŒ‡çº¹

        Args:
            url: ç¼©ç•¥å›¾URL (ä¾‹å¦‚: //pb.plusx.cn/plus/immediate/35272685/2025111623814917/1060536x354blur2.jpg~tplv-...)
            fallback_index: é™çº§æ—¶ä½¿ç”¨çš„ç´¢å¼•ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ–‡ä»¶åæŒ‡çº¹ (ä¾‹å¦‚: "1060536x354blur2.jpg")
        """
        try:
            if not url:
                raise ValueError("URLä¸ºç©º")

            # ä¿®å¤ç›¸å¯¹åè®®URL
            if url.startswith('//'):
                url = 'https:' + url

            # å»é™¤queryå‚æ•°
            path = url.split('?')[0]

            # å…ˆå»é™¤CDNåç¼€ï¼ˆ~ä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼‰ï¼Œå†æå–æ–‡ä»¶å
            # URLæ ¼å¼: //pb.plusx.cn/.../filename.jpg~tplv-.../wst/3:480:1000:gif.avif
            # å¿…é¡»å…ˆæŒ‰~åˆ†å‰²ï¼Œå¦åˆ™ä¼šé”™è¯¯æå–åˆ°æ°´å°å‚æ•°éƒ¨åˆ†
            if '~' in path:
                path = path.split('~')[0]

            # æå–è·¯å¾„æœ€åä¸€æ®µï¼ˆçœŸæ­£çš„æ–‡ä»¶åï¼‰
            filename = path.split('/')[-1]

            if not filename:
                raise ValueError("æå–çš„æ–‡ä»¶åä¸ºç©º")

            return filename

        except Exception as e:
            logging.warning(f"ç¼©ç•¥å›¾URLæå–å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æŒ‡çº¹")
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ—¶é—´æˆ³+ç´¢å¼•
            import random
            if fallback_index is not None:
                return f"fallback_{int(time.time())}_{fallback_index}"
            return f"fallback_{int(time.time())}_{random.randint(1000, 9999)}"

    async def extract_fingerprints_fast(self, page: Page) -> List[Dict[str, str]]:
        """
        å¿«é€Ÿæå–æ‰€æœ‰ç…§ç‰‡çš„æŒ‡çº¹ï¼ˆæ— éœ€ç‚¹å‡»ï¼‰

        Returns:
            [
                {
                    "index": 0,
                    "fingerprint": "1060536x354blur2.jpg",
                    "thumbnail_url": "//pb.plusx.cn/.../1060536x354blur2.jpg~..."
                },
                ...
            ]
        """
        # 1. æ»šåŠ¨åŠ è½½æ‰€æœ‰ç…§ç‰‡
        await scroll_to_load_all(page)

        # 2. è·å–æ‰€æœ‰ç…§ç‰‡å…ƒç´ 
        photo_items = await page.locator(PHOTO_ITEM_SELECTOR).all()
        total_count = len(photo_items)

        logging.info(f"å¼€å§‹å¿«é€Ÿæ‰«æ {total_count} å¼ ç…§ç‰‡çš„æŒ‡çº¹...")

        fingerprints = []

        # 3. é€ä¸ªè¯»å–ç¼©ç•¥å›¾URLå¹¶æå–æŒ‡çº¹
        for idx, photo_item in enumerate(photo_items):
            try:
                # è¯»å–imgå…ƒç´ çš„srcå±æ€§ï¼ˆæ— éœ€ç‚¹å‡»ï¼‰
                img_elem = photo_item.locator("img").first
                thumbnail_url = await img_elem.get_attribute("src")

                if thumbnail_url:
                    # æå–æŒ‡çº¹
                    fingerprint = self._extract_filename_from_thumbnail(thumbnail_url, fallback_index=idx)

                    fingerprints.append({
                        "index": idx,
                        "fingerprint": fingerprint,
                        "thumbnail_url": thumbnail_url
                    })

                    # è°ƒè¯•æ—¥å¿—
                    if DEBUG_FINGERPRINT_EXTRACTION:
                        logging.debug(f"  ç…§ç‰‡ #{idx+1}: æŒ‡çº¹={fingerprint}, URL={thumbnail_url[:80]}...")
                else:
                    logging.warning(f"ç…§ç‰‡ #{idx+1} ç¼©ç•¥å›¾URLä¸ºç©ºï¼Œä½¿ç”¨é™çº§æŒ‡çº¹")
                    fingerprint = self._extract_filename_from_thumbnail("", fallback_index=idx)
                    fingerprints.append({
                        "index": idx,
                        "fingerprint": fingerprint,
                        "thumbnail_url": ""
                    })

            except Exception as e:
                logging.warning(f"æå–ç…§ç‰‡ #{idx+1} æŒ‡çº¹å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æŒ‡çº¹")
                fingerprint = self._extract_filename_from_thumbnail("", fallback_index=idx)
                fingerprints.append({
                    "index": idx,
                    "fingerprint": fingerprint,
                    "thumbnail_url": ""
                })

        logging.info(f"âœ“ æŒ‡çº¹æ‰«æå®Œæˆï¼Œå…± {len(fingerprints)} å¼ ç…§ç‰‡")
        return fingerprints

    async def extract_photo_urls_by_fingerprints(
        self,
        page: Page,
        target_fingerprints: List[str]
    ) -> List[Dict[str, str]]:
        """
        ä»…å¯¹æŒ‡å®šæŒ‡çº¹çš„ç…§ç‰‡è·å–åŸå›¾URLï¼ˆæŒ‰éœ€ç‚¹å‡»ï¼‰

        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            target_fingerprints: éœ€è¦å¤„ç†çš„æŒ‡çº¹åˆ—è¡¨

        Returns:
            [
                {
                    "fingerprint": "1060536x354blur2.jpg",
                    "url": "https://åŸå›¾URL",
                    "filename": "2:30721.jpg",
                    "thumbnail_url": "//ç¼©ç•¥å›¾URL"
                },
                ...
            ]
        """
        if not target_fingerprints:
            logging.info("ç›®æ ‡æŒ‡çº¹åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€æå–")
            return []

        # 1. è·å–æ‰€æœ‰ç…§ç‰‡å…ƒç´ ï¼ˆå·²é€šè¿‡æ»šåŠ¨åŠ è½½ï¼‰
        photo_items = await page.locator(PHOTO_ITEM_SELECTOR).all()

        logging.info(f"å¼€å§‹è·å– {len(target_fingerprints)} å¼ æ–°ç…§ç‰‡çš„åŸå›¾URL...")

        # åˆ›å»ºæŒ‡çº¹é›†åˆç”¨äºå¿«é€ŸæŸ¥æ‰¾
        target_set = set(target_fingerprints)
        photo_urls = []
        processed_count = 0

        # 2. éå†æ‰€æœ‰ç…§ç‰‡å…ƒç´ ï¼Œä»…ç‚¹å‡»ç›®æ ‡æŒ‡çº¹çš„ç…§ç‰‡
        for idx, photo_item in enumerate(photo_items):
            try:
                # è¯»å–ç¼©ç•¥å›¾URLå¹¶æå–æŒ‡çº¹
                img_elem = photo_item.locator("img").first
                thumbnail_url = await img_elem.get_attribute("src")
                fingerprint = self._extract_filename_from_thumbnail(thumbnail_url, fallback_index=idx)

                # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡åˆ—è¡¨ä¸­
                if fingerprint not in target_set:
                    continue  # è·³è¿‡å·²ä¸‹è½½çš„ç…§ç‰‡ï¼ˆæ— éœ€ç‚¹å‡»ï¼‰

                processed_count += 1

                # ç‚¹å‡»ç…§ç‰‡å†…çš„spanå…ƒç´ æ‰“å¼€è¯¦æƒ…
                span_elem = photo_item.locator(PHOTO_CLICK_SELECTOR).first
                await span_elem.click()

                # ç­‰å¾…è¯¦æƒ…åŠ è½½
                await page.wait_for_timeout(PHOTO_DETAIL_LOAD_WAIT)

                # å®šä½view originalé“¾æ¥
                link_elem = page.locator(VIEW_ORIGINAL_SELECTOR).first

                # ç­‰å¾…é“¾æ¥å‡ºç°
                await link_elem.wait_for(timeout=5000)

                # è·å–hrefå±æ€§
                original_url = await link_elem.get_attribute("href")

                if original_url:
                    # ä¿®å¤ç›¸å¯¹åè®®URLï¼ˆ//å¼€å¤´çš„URLéœ€è¦æ·»åŠ https:ï¼‰
                    if original_url.startswith('//'):
                        original_url = 'https:' + original_url

                    # ä»URLæå–æ–‡ä»¶å
                    filename = self._extract_filename_from_url(original_url)
                    photo_urls.append({
                        'fingerprint': fingerprint,
                        'url': original_url,
                        'filename': filename,
                        'thumbnail_url': thumbnail_url or ""
                    })
                    logging.info(f"[{processed_count}/{len(target_fingerprints)}] æå–: {filename} (æŒ‡çº¹: {fingerprint})")

                # å…³é—­è¯¦æƒ…ï¼ˆä½¿ç”¨Escapeé”®ï¼‰
                await page.keyboard.press("Escape")
                await page.wait_for_timeout(PHOTO_CLOSE_WAIT)

            except Exception as e:
                logging.warning(f"æå–ç…§ç‰‡ #{idx+1} å¤±è´¥: {e}")
                # å°è¯•å…³é—­å¯èƒ½æ‰“å¼€çš„è¯¦æƒ…
                try:
                    await page.keyboard.press("Escape")
                except Exception as close_error:
                    logging.debug(f"å…³é—­è¯¦æƒ…å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {close_error}")
                continue

        logging.info(f"âœ“ åŸå›¾URLæå–å®Œæˆï¼ŒæˆåŠŸ {len(photo_urls)}/{len(target_fingerprints)} å¼ ")
        return photo_urls

    def _extract_filename_from_url(self, url: str) -> str:
        """ä»URLæå–æ–‡ä»¶å"""
        # ä»URLä¸­æå–æ–‡ä»¶åï¼Œå»é™¤æŸ¥è¯¢å‚æ•°
        filename = url.split('/')[-1].split('?')[0]

        # å¤„ç†CDNå¤„ç†åçš„æ–‡ä»¶åï¼ˆå¦‚ï¼š9T1A3143.JPG~tplv-xxx.JPGï¼‰
        # ä¿ç•™~ä¹‹å‰çš„åŸå§‹æ–‡ä»¶å
        if '~' in filename:
            filename = filename.split('~')[0]

        return filename


class PhotoDownloader:
    """ä¸‹è½½ç…§ç‰‡ï¼ˆæ”¯æŒæœ¬åœ°å­˜å‚¨å’Œ Dropbox äº‘ç›˜ï¼‰"""

    def __init__(self, photo_dir: str, dropbox_client: Optional[object] = None, dropbox_path: str = ""):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            photo_dir: æœ¬åœ°å­˜å‚¨ç›®å½•
            dropbox_client: Dropbox å®¢æˆ·ç«¯å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            dropbox_path: Dropbox å­˜å‚¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.photo_dir = photo_dir
        self.dropbox_client = dropbox_client
        self.dropbox_path = dropbox_path

        # åˆ›å»ºæœ¬åœ°ç…§ç‰‡ç›®å½•ï¼ˆå¦‚æœéœ€è¦æœ¬åœ°å­˜å‚¨ï¼‰
        if SAVE_TO_LOCAL:
            os.makedirs(photo_dir, exist_ok=True)

    def download_photo(self, url: str, filename: str) -> bool:
        """
        ä¸‹è½½å•å¼ ç…§ç‰‡åˆ°å†…å­˜ï¼Œç„¶åæ ¹æ®é…ç½®ä¿å­˜åˆ° Dropbox å’Œ/æˆ–æœ¬åœ°

        Args:
            url: ç…§ç‰‡ URL
            filename: æ–‡ä»¶å

        Returns:
            True è¡¨ç¤ºä¸‹è½½æˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        photo_data = None

        # 1. ä¸‹è½½ç…§ç‰‡åˆ°å†…å­˜
        for attempt in range(1, MAX_DOWNLOAD_RETRIES + 1):
            try:
                response = requests.get(url, timeout=30, stream=True)
                response.raise_for_status()

                # ä¸‹è½½åˆ°å†…å­˜ç¼“å†²åŒº
                photo_data = BytesIO()
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        photo_data.write(chunk)

                logging.info(f"âœ“ ä¸‹è½½åˆ°å†…å­˜: {filename} ({photo_data.tell()} å­—èŠ‚)")
                break  # ä¸‹è½½æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                if attempt < MAX_DOWNLOAD_RETRIES:
                    logging.warning(
                        f"âœ— ä¸‹è½½å¤±è´¥ (å°è¯• {attempt}/{MAX_DOWNLOAD_RETRIES}): {filename} - {e}"
                    )
                    time.sleep(2)
                else:
                    logging.error(f"âœ— ä¸‹è½½å¤±è´¥å·²è·³è¿‡: {filename} - {e}")
                    return False

        if not photo_data:
            return False

        # 2. ä¸Šä¼ åˆ° Dropboxï¼ˆå¦‚æœé…ç½®ï¼‰
        if self.dropbox_client:
            upload_success = self._upload_to_dropbox(photo_data, filename)
            if not upload_success:
                logging.warning(f"Dropbox ä¸Šä¼ å¤±è´¥: {filename}")
                return False  # ä¸Šä¼ å¤±è´¥åˆ™è·³è¿‡æ­¤ç…§ç‰‡

        # 3. ä¿å­˜åˆ°æœ¬åœ°ï¼ˆå¦‚æœé…ç½®ï¼‰
        if SAVE_TO_LOCAL:
            self._save_to_local(photo_data, filename)

        return True

    def _upload_to_dropbox(self, photo_data: BytesIO, filename: str) -> bool:
        """
        ä¸Šä¼ ç…§ç‰‡åˆ° Dropboxï¼Œæ”¯æŒé‡è¯•

        Args:
            photo_data: ç…§ç‰‡æ•°æ®ï¼ˆBytesIO å¯¹è±¡ï¼‰
            filename: æ–‡ä»¶å

        Returns:
            True è¡¨ç¤ºä¸Šä¼ æˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        if not self.dropbox_client:
            return False

        for attempt in range(1, MAX_DOWNLOAD_RETRIES + 1):
            try:
                # é‡ç½®æŒ‡é’ˆåˆ°å¼€å¤´
                photo_data.seek(0)

                # æ„å»º Dropbox æ–‡ä»¶è·¯å¾„
                dropbox_file_path = f"{self.dropbox_path}/{filename}"

                # ä¸Šä¼ æ–‡ä»¶
                self.dropbox_client.files_upload(
                    photo_data.read(),
                    dropbox_file_path,
                    mode=dropbox.files.WriteMode.overwrite
                )

                logging.info(f"âœ“ å·²ä¸Šä¼ åˆ° Dropbox: {dropbox_file_path}")
                return True

            except Exception as e:
                if attempt < MAX_DOWNLOAD_RETRIES:
                    logging.warning(
                        f"âœ— Dropbox ä¸Šä¼ å¤±è´¥ (å°è¯• {attempt}/{MAX_DOWNLOAD_RETRIES}): {filename} - {e}"
                    )
                    time.sleep(2)
                else:
                    logging.error(f"âœ— Dropbox ä¸Šä¼ å¤±è´¥å·²è·³è¿‡: {filename} - {e}")

        return False

    def _save_to_local(self, photo_data: BytesIO, filename: str) -> bool:
        """
        ä¿å­˜ç…§ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ

        Args:
            photo_data: ç…§ç‰‡æ•°æ®ï¼ˆBytesIO å¯¹è±¡ï¼‰
            filename: æ–‡ä»¶å

        Returns:
            True è¡¨ç¤ºä¿å­˜æˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        try:
            # é‡ç½®æŒ‡é’ˆåˆ°å¼€å¤´
            photo_data.seek(0)

            # æ„å»ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(self.photo_dir, filename)

            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'wb') as f:
                f.write(photo_data.read())

            logging.info(f"âœ“ å·²ä¿å­˜åˆ°æœ¬åœ°: {file_path}")
            return True

        except Exception as e:
            logging.error(f"âœ— ä¿å­˜åˆ°æœ¬åœ°å¤±è´¥: {filename} - {e}")
            return False


def initialize_environment() -> None:
    """
    ç³»ç»Ÿç¯å¢ƒåˆå§‹åŒ–

    æ ¹æ® config.FRESH_START é…ç½®å†³å®šæ˜¯å¦æ¸…é™¤å†å²æ•°æ®:
    - True: åˆ é™¤ downloaded.json å’Œ photos/ ç›®å½•ä¸‹æ‰€æœ‰ç…§ç‰‡æ–‡ä»¶
    - False: ä¿æŒç°æœ‰æ•°æ®ä¸å˜

    Raises:
        SystemExit: æ¸…ç†å¤±è´¥æ—¶ç»ˆæ­¢ç¨‹åºï¼ˆé€€å‡ºç  1ï¼‰
    """
    if not FRESH_START:
        logging.info("ç»§ç»­ä½¿ç”¨ç°æœ‰å†å²è®°å½•")
        return

    logging.info("âš ï¸  FRESH_START æ¨¡å¼å·²å¯ç”¨ï¼Œå¼€å§‹æ¸…ç†å†å²æ•°æ®...")

    try:
        # 1. åˆ é™¤å†å²è®°å½•æ–‡ä»¶
        if os.path.exists(DOWNLOADED_HISTORY):
            os.remove(DOWNLOADED_HISTORY)
            logging.info(f"âœ“ å·²åˆ é™¤å†å²è®°å½•æ–‡ä»¶: {DOWNLOADED_HISTORY}")
        else:
            logging.info(f"- å†å²è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {DOWNLOADED_HISTORY}")

        # 2. åˆ é™¤ photos ç›®å½•ä¸‹æ‰€æœ‰ç…§ç‰‡æ–‡ä»¶
        if os.path.exists(PHOTO_DIR):
            deleted_count = 0
            for filename in os.listdir(PHOTO_DIR):
                file_path = os.path.join(PHOTO_DIR, filename)
                # åªåˆ é™¤æ–‡ä»¶ï¼Œä¿ç•™å­ç›®å½•
                if os.path.isfile(file_path):
                    os.remove(file_path)
                    deleted_count += 1
            logging.info(f"âœ“ å·²åˆ é™¤ {deleted_count} å¼ å†å²ç…§ç‰‡")
        else:
            logging.info(f"- ç…§ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {PHOTO_DIR}")

        logging.info("âœ… å†å²æ•°æ®æ¸…ç†å®Œæˆï¼Œå°†ä»å…¨æ–°çŠ¶æ€å¯åŠ¨")

    except PermissionError as e:
        logging.error(f"âŒ æ¸…ç†å¤±è´¥: æ–‡ä»¶æƒé™ä¸è¶³ - {e}")
        sys.exit(1)
    except OSError as e:
        logging.error(f"âŒ æ¸…ç†å¤±è´¥: æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ - {e}")
        sys.exit(1)
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†å¤±è´¥: æœªçŸ¥é”™è¯¯ - {e}")
        sys.exit(1)


async def main():
    """ä¸»ç¨‹åºå¾ªç¯"""

    # ç³»ç»Ÿç¯å¢ƒåˆå§‹åŒ–ï¼ˆæ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ¸…é™¤å†å²æ•°æ®ï¼‰
    initialize_environment()

    # åˆå§‹åŒ– Dropbox å®¢æˆ·ç«¯
    dropbox_client = None
    if DROPBOX_ACCESS_TOKEN:
        logging.info("æ­£åœ¨åˆå§‹åŒ– Dropbox å®¢æˆ·ç«¯...")
        dropbox_client = init_dropbox_client(DROPBOX_ACCESS_TOKEN)
        if dropbox_client:
            # ç¡®ä¿ Dropbox è·¯å¾„å­˜åœ¨
            path_ready = ensure_dropbox_path(dropbox_client, DROPBOX_SAVE_PATH)
            if not path_ready:
                logging.warning("Dropbox è·¯å¾„åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç¦ç”¨ Dropbox åŠŸèƒ½")
                dropbox_client = None
        else:
            logging.warning("Dropbox å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨æœ¬åœ°å­˜å‚¨")

    # åˆå§‹åŒ–ç»„ä»¶
    history = DownloadHistory(DOWNLOADED_HISTORY)
    downloader = PhotoDownloader(
        PHOTO_DIR,
        dropbox_client=dropbox_client,
        dropbox_path=DROPBOX_SAVE_PATH
    )
    extractor = PhotoExtractor()

    connection_failures = 0

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    logging.info(SEPARATOR)
    logging.info("PhotoPlus ç…§ç‰‡è‡ªåŠ¨ä¸‹è½½å·¥å…·å¯åŠ¨ (v2.0 - æŒ‡çº¹å»é‡)")
    logging.info(f"ç›®æ ‡URL: {TARGET_URL}")
    logging.info(f"æ£€æŸ¥é—´éš”: {CHECK_INTERVAL}ç§’")

    # å­˜å‚¨é…ç½®ä¿¡æ¯
    if dropbox_client:
        logging.info(f"Dropbox å­˜å‚¨: å·²å¯ç”¨ â†’ {DROPBOX_SAVE_PATH}")
        if SAVE_TO_LOCAL:
            logging.info(f"æœ¬åœ°å­˜å‚¨: å·²å¯ç”¨ â†’ {PHOTO_DIR}")
        else:
            logging.info(f"æœ¬åœ°å­˜å‚¨: å·²ç¦ç”¨ï¼ˆä»…ä¿å­˜åˆ° Dropboxï¼‰")
    else:
        logging.info(f"Dropbox å­˜å‚¨: æœªé…ç½®")
        logging.info(f"æœ¬åœ°å­˜å‚¨: {PHOTO_DIR}")

    logging.info(f"å·²åŠ è½½å†å²è®°å½•: {len(history.downloads)} å¼ ç…§ç‰‡")
    logging.info(SEPARATOR)

    # å¯åŠ¨Playwright
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=HEADLESS)
        # ç¦ç”¨æµè§ˆå™¨ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è·å–æœ€æ–°æ•°æ®
        context = await browser.new_context(
            extra_http_headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0'
            }
        )
        page = await context.new_page()

        # è®¾ç½®è¶…æ—¶æ—¶é—´
        page.set_default_timeout(TIMEOUT)

        try:
            loop_count = 0  # å¾ªç¯è®¡æ•°å™¨
            while True:
                try:
                    # 1. è®¿é—®/åˆ·æ–°é¡µé¢
                    if loop_count == 0:
                        # é¦–æ¬¡è®¿é—®
                        logging.info("\næ­£åœ¨è®¿é—®é¡µé¢...")
                        await page.goto(TARGET_URL, wait_until="networkidle")
                    else:
                        # åç»­åˆ·æ–°
                        logging.info("\næ­£åœ¨åˆ·æ–°é¡µé¢...")
                        await page.reload(wait_until="networkidle")

                    loop_count += 1
                    await page.wait_for_timeout(PAGE_RENDER_WAIT)

                    connection_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                    if loop_count == 1:
                        logging.info("âœ“ é¡µé¢é¦–æ¬¡åŠ è½½æˆåŠŸ")
                    else:
                        logging.info(f"âœ“ é¡µé¢åˆ·æ–°æˆåŠŸï¼ˆç¬¬ {loop_count} æ¬¡å¾ªç¯ï¼‰")

                    # 2. å¿«é€Ÿæ‰«ææ‰€æœ‰ç…§ç‰‡æŒ‡çº¹ï¼ˆæ— ç‚¹å‡»å¼€é”€ï¼‰
                    logging.info("\næ­£åœ¨æ‰«æç…§ç‰‡æŒ‡çº¹...")
                    all_fingerprints = await extractor.extract_fingerprints_fast(page)
                    total_count = len(all_fingerprints)

                    # 3. è¯†åˆ«æœªä¸‹è½½çš„ç…§ç‰‡
                    unknown_items = [
                        item for item in all_fingerprints
                        if not history.is_downloaded_by_fingerprint(item['fingerprint'])
                    ]
                    new_count = len(unknown_items)
                    downloaded_count = total_count - new_count

                    logging.info(f"\næ‰«æç»“æœ:")
                    logging.info(f"  - æ€»è®¡: {total_count} å¼ ç…§ç‰‡")
                    logging.info(f"  - å·²ä¸‹è½½: {downloaded_count} å¼ ")
                    logging.info(f"  - æ–°ç…§ç‰‡: {new_count} å¼ ")

                    # 4. ä»…å¯¹æ–°ç…§ç‰‡è·å–åŸå›¾URLå¹¶ä¸‹è½½
                    if new_count > 0:
                        logging.info(f"\nå¼€å§‹ä¸‹è½½ {new_count} å¼ æ–°ç…§ç‰‡...")

                        # è·å–æ–°ç…§ç‰‡çš„åŸå›¾URL
                        new_photos = await extractor.extract_photo_urls_by_fingerprints(
                            page,
                            [item['fingerprint'] for item in unknown_items]
                        )

                        success_count = 0
                        for idx, photo in enumerate(new_photos, 1):
                            logging.info(f"\n[{idx}/{new_count}] ä¸‹è½½: {photo['filename']}")

                            # ä¸‹è½½ç…§ç‰‡
                            success = downloader.download_photo(
                                photo['url'],
                                photo['filename']
                            )

                            if success:
                                # è®°å½•ä¸‹è½½ä¿¡æ¯ï¼ˆæŒ‡çº¹+åŸå›¾æ–‡ä»¶å+ç¼©ç•¥å›¾URLï¼‰
                                history.add_download_record(
                                    fingerprint=photo['fingerprint'],
                                    original_filename=photo['filename'],
                                    thumbnail_url=photo['thumbnail_url']
                                )
                                success_count += 1

                        # 5. ä¿å­˜å†å²è®°å½•
                        history.save_history()
                        logging.info(f"\nâœ“ æœ¬æ¬¡ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ {success_count}/{new_count} å¼ ç…§ç‰‡")
                        logging.info(f"å†å²è®°å½•å·²æ›´æ–°: {len(history.downloads)} å¼ ç…§ç‰‡")
                    else:
                        logging.info("\næ²¡æœ‰æ–°ç…§ç‰‡éœ€è¦ä¸‹è½½")

                    # 6. ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                    logging.info(f"\nç­‰å¾… {CHECK_INTERVAL} ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æ£€æŸ¥...")
                    logging.info(SEPARATOR)
                    await asyncio.sleep(CHECK_INTERVAL)

                except Exception as e:
                    connection_failures += 1
                    logging.error(
                        f"\nâœ— è®¿é—®å¤±è´¥ ({connection_failures}/{MAX_CONNECTION_FAILURES}): {e}"
                    )

                    if connection_failures >= MAX_CONNECTION_FAILURES:
                        logging.error("è¿æ¥å¤±è´¥æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼Œç¨‹åºé€€å‡º")
                        break

                    logging.info(f"ç­‰å¾…10ç§’åé‡è¯•...")
                    await asyncio.sleep(10)

        except KeyboardInterrupt:
            logging.info("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")

        finally:
            await browser.close()
            logging.info("ç¨‹åºå·²é€€å‡º")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²ç»ˆæ­¢")
